diff -rcNP linux-3.14.4/include/linux/mm_types.h linux-3.14.4-memSwap/include/linux/mm_types.h
*** linux-3.14.4/include/linux/mm_types.h	2014-05-13 07:33:14.000000000 -0400
--- linux-3.14.4-memSwap/include/linux/mm_types.h	2016-07-15 09:49:20.000000000 -0400
***************
*** 195,200 ****
--- 195,205 ----
  #ifdef LAST_CPUPID_NOT_IN_PAGE_FLAGS
  	int _last_cpupid;
  #endif
+ 
+ 	int idx;
+ 	unsigned long rmap_addrs[10];
+ 	struct vm_area_struct* rmap_vmas[10];
+ 
  }
  /*
   * The struct page can be forced to be double word aligned so that atomic ops
diff -rcNP linux-3.14.4/include/linux/swapfile.h linux-3.14.4-memSwap/include/linux/swapfile.h
*** linux-3.14.4/include/linux/swapfile.h	2014-05-13 07:33:14.000000000 -0400
--- linux-3.14.4-memSwap/include/linux/swapfile.h	2016-07-15 15:08:51.000000000 -0400
***************
*** 10,13 ****
--- 10,15 ----
  extern struct swap_info_struct *swap_info[];
  extern int try_to_unuse(unsigned int, bool, unsigned long);
  
+ void set_memswap_init_size(unsigned long init_size);
+ 
  #endif /* _LINUX_SWAPFILE_H */
diff -rcNP linux-3.14.4/include/linux/swap.h linux-3.14.4-memSwap/include/linux/swap.h
*** linux-3.14.4/include/linux/swap.h	2014-05-13 07:33:14.000000000 -0400
--- linux-3.14.4-memSwap/include/linux/swap.h	2016-09-10 21:58:55.888286000 -0400
***************
*** 253,258 ****
--- 253,278 ----
  	struct work_struct discard_work; /* discard worker */
  	struct swap_cluster_info discard_cluster_head; /* list head of discard clusters */
  	struct swap_cluster_info discard_cluster_tail; /* list tail of discard clusters */
+ 	
+ 	char *shm; /*swap to (shared) memory*/
+        
+ 	unsigned long *mapper; /*mapping from contiguous address to non-continguous in the shared memory*/
+ 	unsigned long shm_start;
+         unsigned long shm_end;
+         unsigned long disk_start;
+         unsigned long disk_end;
+         unsigned long mask;
+ 	int is_shm;
+ 	int dump_thread_running;
+ 	int dump_thread_should_run;
+ 	spinlock_t dump_lock;
+ 
+ };
+ 
+ struct swapin_mdata{
+         struct vm_area_struct *vma;
+         pmd_t *pmd;
+         unsigned long address;
  };
  
  struct swap_list_t {
diff -rcNP linux-3.14.4/mm/page_io.c linux-3.14.4-memSwap/mm/page_io.c
*** linux-3.14.4/mm/page_io.c	2014-05-13 07:33:14.000000000 -0400
--- linux-3.14.4-memSwap/mm/page_io.c	2016-09-05 10:46:20.237538719 -0400
***************
*** 24,29 ****
--- 24,63 ----
  #include <linux/blkdev.h>
  #include <asm/pgtable.h>
  
+ typedef int (* swap_writepage_hook)(struct page *page, struct writeback_control *wbc, void (*end_write_func)(struct bio *, int));
+ 
+ typedef int (* swap_readpage_hook)(struct page *page);
+ 
+ typedef struct swapin_mdata* (* get_swapin_mdata_hook)(unsigned long offset);
+ 
+ bool mempipe_installed = false;
+ int (* __my_swap_writepage)(struct page *page, struct writeback_control *wbc, void (*end_write_func)(struct bio *, int)) = NULL;
+ int (* __my_swap_readpage)(struct page *page) = NULL;
+ struct swapin_mdata* (* __my_get_swapin_mdata)(unsigned long offset) = NULL;
+ 
+ void swap_bind_hook(swap_writepage_hook h1, swap_readpage_hook h2, get_swapin_mdata_hook h3)                                                                     
+ {
+         mempipe_installed = true;
+         __my_swap_writepage = h1;
+         __my_swap_readpage = h2;
+         __my_get_swapin_mdata = h3;
+         printk("Qi Zhang: swap_bind_hook...\n");
+ }
+ 
+ void swap_unbind_hook(void)
+ {
+         mempipe_installed = false;
+         __my_swap_writepage = NULL;
+         __my_swap_readpage = NULL;
+         __my_get_swapin_mdata = NULL;
+         printk("Qi Zhang: swap_unbind_hook...\n");
+ }
+ 
+ EXPORT_SYMBOL(swap_bind_hook);
+ EXPORT_SYMBOL(swap_unbind_hook);
+ 
+ 
+ 
  static struct bio *get_swap_bio(gfp_t gfp_flags,
  				struct page *page, bio_end_io_t end_io)
  {
***************
*** 42,47 ****
--- 76,82 ----
  	}
  	return bio;
  }
+ EXPORT_SYMBOL(get_swap_bio);
  
  void end_swap_bio_write(struct bio *bio, int err)
  {
***************
*** 68,73 ****
--- 103,109 ----
  	end_page_writeback(page);
  	bio_put(bio);
  }
+ EXPORT_SYMBOL(end_swap_bio_write);
  
  void end_swap_bio_read(struct bio *bio, int err)
  {
***************
*** 132,137 ****
--- 168,174 ----
  	unlock_page(page);
  	bio_put(bio);
  }
+ EXPORT_SYMBOL(end_swap_bio_read);
  
  int generic_swapfile_activate(struct swap_info_struct *sis,
  				struct file *swap_file,
***************
*** 232,237 ****
--- 269,278 ----
  int swap_writepage(struct page *page, struct writeback_control *wbc)
  {
  	int ret = 0;
+ 	pgoff_t offset;
+ 	swp_entry_t entry;
+ 
+ 	struct swap_info_struct *sis = page_swap_info(page);
  
  	if (try_to_free_swap(page)) {
  		unlock_page(page);
***************
*** 243,249 ****
  		end_page_writeback(page);
  		goto out;
  	}
! 	ret = __swap_writepage(page, wbc, end_swap_bio_write);
  out:
  	return ret;
  }
--- 284,298 ----
  		end_page_writeback(page);
  		goto out;
  	}
! 	
! 	entry.val = page_private(page);
!         offset = swp_offset(entry);
! 
! 	if(mempipe_installed == true && sis->is_shm == 1 && (offset > 0)){
!                 ret = __my_swap_writepage(page, wbc, end_swap_bio_write);
!         }else{
!                 ret = __swap_writepage(page, wbc, end_swap_bio_write);
!         }
  out:
  	return ret;
  }
diff -rcNP linux-3.14.4/mm/page-writeback.c linux-3.14.4-memSwap/mm/page-writeback.c
*** linux-3.14.4/mm/page-writeback.c	2014-05-13 07:33:14.000000000 -0400
--- linux-3.14.4-memSwap/mm/page-writeback.c	2016-08-20 18:37:35.113995160 -0400
***************
*** 2376,2381 ****
--- 2376,2386 ----
  
  		spin_lock_irqsave(&mapping->tree_lock, flags);
  		ret = TestClearPageWriteback(page);
+ 		
+ 		if(!ret){
+ 			printk("~~~~~~~~~~~~~~ ret1 = %d\n", ret);
+ 		}
+ 		
  		if (ret) {
  			radix_tree_tag_clear(&mapping->page_tree,
  						page_index(page),
***************
*** 2388,2393 ****
--- 2393,2402 ----
  		spin_unlock_irqrestore(&mapping->tree_lock, flags);
  	} else {
  		ret = TestClearPageWriteback(page);
+ 		
+ 		if(!ret){
+ 			printk("~~~~~~~~~~~~~~ ret1 = %d\n", ret);
+ 		}
  	}
  	if (ret) {
  		mem_cgroup_dec_page_stat(page, MEM_CGROUP_STAT_WRITEBACK);
diff -rcNP linux-3.14.4/mm/rmap.c linux-3.14.4-memSwap/mm/rmap.c
*** linux-3.14.4/mm/rmap.c	2014-05-13 07:33:14.000000000 -0400
--- linux-3.14.4-memSwap/mm/rmap.c	2016-07-15 09:56:26.000000000 -0400
***************
*** 60,65 ****
--- 60,67 ----
  
  #include <asm/tlbflush.h>
  
+ #include <asm/pgtable.h>
+ 
  #include "internal.h"
  
  static struct kmem_cache *anon_vma_cachep;
***************
*** 617,622 ****
--- 619,631 ----
  		return NULL;
  
  	pte = pte_offset_map(pmd, address);
+ 	
+ 	/*Sometimes, we need the value of pte even if it is not present*/
+ 	if(sync == 8888){
+                 pte_unmap(pte);
+                 return pte;
+         }
+ 
  	/* Make a quick check before getting the lock */
  	if (!sync && !pte_present(*pte)) {
  		pte_unmap(pte);
***************
*** 1607,1612 ****
--- 1616,1623 ----
  	if (!anon_vma)
  		return ret;
  
+ 	page->idx = 0;
+ 
  	anon_vma_interval_tree_foreach(avc, &anon_vma->rb_root, pgoff, pgoff) {
  		struct vm_area_struct *vma = avc->vma;
  		unsigned long address = vma_address(page, vma);
***************
*** 1615,1620 ****
--- 1626,1639 ----
  			continue;
  
  		ret = rwc->rmap_one(page, vma, address, rwc->arg);
+ 		
+ 		if(page->idx < 10) {
+                         page->rmap_addrs[page->idx] = address;
+                         page->rmap_vmas[page->idx] = vma;
+                         page->idx++;
+                 }
+ 
+ 
  		if (ret != SWAP_AGAIN)
  			break;
  		if (rwc->done && rwc->done(page))
diff -rcNP linux-3.14.4/mm/swapfile.c linux-3.14.4-memSwap/mm/swapfile.c
*** linux-3.14.4/mm/swapfile.c	2014-05-13 07:33:14.000000000 -0400
--- linux-3.14.4-memSwap/mm/swapfile.c	2016-09-11 21:16:21.718328183 -0400
***************
*** 46,51 ****
--- 46,77 ----
  static sector_t map_swap_entry(swp_entry_t, struct block_device**);
  
  DEFINE_SPINLOCK(swap_lock);
+ 
+ EXPORT_SYMBOL(swap_lock);
+ 
+ /*Initial size of memswap*/
+ static unsigned long memswap_init_size;
+ static int next_swap = 0;
+ 
+ void set_memswap_init_size(unsigned long init_size){
+ 	memswap_init_size = init_size;
+ }
+ EXPORT_SYMBOL(set_memswap_init_size);
+ 
+ void switch_to_next_swap(void){
+ 	next_swap = 1;
+ }
+ EXPORT_SYMBOL(switch_to_next_swap);
+ 
+ void back_to_default_swap(void){
+ 	next_swap = 0;
+ }
+ EXPORT_SYMBOL(back_to_default_swap);
+ //#define PAGE_NUMS (1<<18) //256K pages -> 1GB
+ 
+ extern struct swapin_mdata * (* __my_get_swapin_mdata)(unsigned long offset);
+ extern bool mempipe_installed;
+ 
  static unsigned int nr_swapfiles;
  atomic_long_t nr_swap_pages;
  /* protected with swap_lock. reading in vm_swap_full() doesn't need lock */
***************
*** 467,479 ****
  }
  
  static unsigned long scan_swap_map(struct swap_info_struct *si,
! 				   unsigned char usage)
  {
  	unsigned long offset;
  	unsigned long scan_base;
  	unsigned long last_in_cluster = 0;
  	int latency_ration = LATENCY_LIMIT;
  
  	/*
  	 * We try to cluster swap pages by allocating them sequentially
  	 * in swap.  Once we've allocated SWAPFILE_CLUSTER pages this
--- 493,508 ----
  }
  
  static unsigned long scan_swap_map(struct swap_info_struct *si,
! 				   unsigned char usage,
! 				   int type)
  {
  	unsigned long offset;
  	unsigned long scan_base;
  	unsigned long last_in_cluster = 0;
  	int latency_ration = LATENCY_LIMIT;
  
+ 	if((type == 0)&&(next_swap == 1))
+ 		goto no_page;
  	/*
  	 * We try to cluster swap pages by allocating them sequentially
  	 * in swap.  Once we've allocated SWAPFILE_CLUSTER pages this
***************
*** 694,703 ****
  
  		spin_unlock(&swap_lock);
  		/* This is called for allocating swap entry for cache */
! 		offset = scan_swap_map(si, SWAP_HAS_CACHE);
  		spin_unlock(&si->lock);
! 		if (offset)
  			return swp_entry(type, offset);
  		spin_lock(&swap_lock);
  		next = swap_list.next;
  	}
--- 723,734 ----
  
  		spin_unlock(&swap_lock);
  		/* This is called for allocating swap entry for cache */
! 		
! 		offset = scan_swap_map(si, SWAP_HAS_CACHE, type);
  		spin_unlock(&si->lock);
! 		if (offset){
  			return swp_entry(type, offset);
+ 		}
  		spin_lock(&swap_lock);
  		next = swap_list.next;
  	}
***************
*** 719,725 ****
  	if (si && (si->flags & SWP_WRITEOK)) {
  		atomic_long_dec(&nr_swap_pages);
  		/* This is called for allocating swap entry, not cache */
! 		offset = scan_swap_map(si, 1);
  		if (offset) {
  			spin_unlock(&si->lock);
  			return swp_entry(type, offset);
--- 750,756 ----
  	if (si && (si->flags & SWP_WRITEOK)) {
  		atomic_long_dec(&nr_swap_pages);
  		/* This is called for allocating swap entry, not cache */
! 		offset = scan_swap_map(si, 1, type);
  		if (offset) {
  			spin_unlock(&si->lock);
  			return swp_entry(type, offset);
***************
*** 1364,1369 ****
--- 1395,1407 ----
  	unsigned int i = 0;
  	int retval = 0;
  
+ 	struct swapin_mdata* sm = NULL;
+ 	unsigned long index1 = 0, index2 = 0, index3 = 0;
+         long long total0 = 0, total1 = 0, total2 = 0, total3 = 0;
+         ktime_t start0, start1, start2, start3, end0, end1, end2, end3;
+ 
+ 	start0 = ktime_get();
+ 	
  	/*
  	 * When searching mms for an entry, a good strategy is to
  	 * start at the first mm we freed the previous entry from
***************
*** 1386,1397 ****
--- 1424,1437 ----
  	 * one pass through swap_map is enough, but not necessarily:
  	 * there are races when an instance of an entry might be missed.
  	 */
+ 
  	while ((i = find_next_to_unuse(si, i, frontswap)) != 0) {
  		if (signal_pending(current)) {
  			retval = -EINTR;
  			break;
  		}
  
+ 		//__asm__ volatile (".byte 0x0f, 0x31" : "=A" (start1));
  		/*
  		 * Get a page for the entry, using the existing swap
  		 * cache page if there is one.  Otherwise, get a clean
***************
*** 1399,1406 ****
--- 1439,1450 ----
  		 */
  		swap_map = &si->swap_map[i];
  		entry = swp_entry(type, i);
+ 		
+ 		//__asm__ volatile (".byte 0x0f, 0x31" : "=A" (start2));
+ 		start2 = ktime_get();
  		page = read_swap_cache_async(entry,
  					GFP_HIGHUSER_MOVABLE, NULL, 0);
+ 
  		if (!page) {
  			/*
  			 * Either swap_duplicate() failed because entry
***************
*** 1419,1430 ****
--- 1463,1480 ----
  			if (!swcount || swcount == SWAP_MAP_BAD)
  				continue;
  			retval = -ENOMEM;
+ 			
  			break;
  		}
  
+         	//__asm__ volatile (".byte 0x0f, 0x31" : "=A" (end2));
+ 		end2 = ktime_get();
+ 		total2 += ktime_to_ns(ktime_sub(end2, start2));
+ 		index2++;		
  		/*
  		 * Don't hold on to start_mm if it looks like exiting.
  		 */
+ 		start1 = ktime_get();	
  		if (atomic_read(&start_mm->mm_users) == 1) {
  			mmput(start_mm);
  			start_mm = &init_mm;
***************
*** 1441,1446 ****
--- 1491,1497 ----
  		 */
  		wait_on_page_locked(page);
  		wait_on_page_writeback(page);
+ 		
  		lock_page(page);
  		wait_on_page_writeback(page);
  
***************
*** 1455,1463 ****
--- 1506,1545 ----
  				break;
  			continue;
  		}
+                 end1 = ktime_get();
+ 		total1 += ktime_to_ns(ktime_sub(end1, start1));/*index does not increase here, another start1/end1 at the end of this func*/
+ 
+ 		//__asm__ volatile (".byte 0x0f, 0x31" : "=A" (start3));
+ 		start3 = ktime_get();	
+ 		/*
  		if (swap_count(swcount) && start_mm != &init_mm)
  			retval = unuse_mm(start_mm, entry, page);
+ 		*/
  
+ 		if(mempipe_installed == false || si->is_shm == 0) {
+                         if (swap_count(swcount) && start_mm != &init_mm)
+                                 retval = unuse_mm(start_mm, entry, page);
+                 }else{
+                         if (swap_count(swcount) && start_mm != &init_mm) {
+                                 sm = __my_get_swapin_mdata(i);
+                                 if(sm == NULL) {
+                                         retval = unuse_mm(start_mm, entry, page);
+                                 }else{
+                                         retval = unuse_pte(sm->vma, sm->pmd, sm->address, entry, page);
+                                         retval = (retval < 0)?retval:0;
+                                 }
+ 
+                         }
+                 }
+ 
+                 //__asm__ volatile (".byte 0x0f, 0x31" : "=A" (end3));
+ 		//total3 += end3 - start3;
+ 		end3 = ktime_get();
+ 		total3 += ktime_to_ns(ktime_sub(end3, start3));
+                 index3++;
+ 
+ 		//__asm__ volatile (".byte 0x0f, 0x31" : "=A" (start1));
+ 		start1 = ktime_get();
  		if (swap_count(*swap_map)) {
  			int set_start_mm = (*swap_map >= swcount);
  			struct list_head *p = &start_mm->mmlist;
***************
*** 1565,1573 ****
--- 1647,1672 ----
  			if (!--pages_to_unuse)
  				break;
  		}
+ 
+                 //__asm__ volatile (".byte 0x0f, 0x31" : "=A" (end1));
+ 		//total1 += end1 - start1;
+                 end1 = ktime_get();
+ 		total1 += ktime_to_ns(ktime_sub(end1, start1));
+ 		index1++;
  	}
  
  	mmput(start_mm);
+ 	//__asm__ volatile (".byte 0x0f, 0x31" : "=A" (end0));
+ 	//total0 += end0 - start0;
+ 	end0 = ktime_get();
+ 	total0 = ktime_to_ns(ktime_sub(end0, start0));
+ 
+ 	printk("index1 = %ld, index2 = %ld, inde3 = %ld\n", index1, index2, index3);
+ 	if(index1&&index2&&index3 != 0){
+ 		printk("total = %lld\n", total0);
+ 		printk("perpage: read = %lld, unuse_mm = %lld, other = %lld\n", total2/index2, total3/index3, total1/index1);
+ 	}
+ 
  	return retval;
  }
  
***************
*** 1634,1640 ****
  	entry.val = page_private(page);
  	return map_swap_entry(entry, bdev);
  }
! 
  /*
   * Free all of a swapdev's extent information
   */
--- 1733,1739 ----
  	entry.val = page_private(page);
  	return map_swap_entry(entry, bdev);
  }
! EXPORT_SYMBOL(map_swap_page);
  /*
   * Free all of a swapdev's extent information
   */
***************
*** 1855,1860 ****
--- 1954,1960 ----
  	if (type < 0) {
  		err = -EINVAL;
  		spin_unlock(&swap_lock);
+ 		printk("swapoff 1...\n");
  		goto out_dput;
  	}
  	if (!security_vm_enough_memory_mm(current->mm, p->pages))
***************
*** 1862,1867 ****
--- 1962,1968 ----
  	else {
  		err = -ENOMEM;
  		spin_unlock(&swap_lock);
+ 		printk("swapoff 2...\n");
  		goto out_dput;
  	}
  	if (prev < 0)
***************
*** 1907,1912 ****
--- 2008,2014 ----
  
  	/* wait for anyone still in scan_swap_map */
  	p->highest_bit = 0;		/* cuts scans short */
+ 	/*
  	while (p->flags >= SWP_SCANNING) {
  		spin_unlock(&p->lock);
  		spin_unlock(&swap_lock);
***************
*** 1914,1919 ****
--- 2016,2022 ----
  		spin_lock(&swap_lock);
  		spin_lock(&p->lock);
  	}
+ 	*/
  
  	swap_file = p->swap_file;
  	old_block_size = p->old_block_size;
***************
*** 2228,2239 ****
--- 2331,2345 ----
  	 */
  	maxpages = swp_offset(pte_to_swp_entry(
  			swp_entry_to_pte(swp_entry(0, ~0UL)))) + 1;
+ 
  	last_page = swap_header->info.last_page;
+ 
  	if (last_page > maxpages) {
  		pr_warn("Truncating oversized swap area, only using %luk out of %luk\n",
  			maxpages << (PAGE_SHIFT - 10),
  			last_page << (PAGE_SHIFT - 10));
  	}
+ 	
  	if (maxpages > last_page) {
  		maxpages = last_page + 1;
  		/* p->max is an unsigned int: don't overflow it */
***************
*** 2245,2250 ****
--- 2351,2365 ----
  	if (!maxpages)
  		return 0;
  	swapfilepages = i_size_read(inode) >> PAGE_SHIFT;
+ 	
+ 	//printk("swapfilepages = %lu, maxpages = %lu\n", swapfilepages, maxpages);
+ 
+ 	if(maxpages > swapfilepages){
+ 		maxpages = swapfilepages;
+ 		swap_header->info.last_page = maxpages - 1;
+ 		last_page = maxpages - 1;
+ 	}
+ 
  	if (swapfilepages && maxpages > swapfilepages) {
  		pr_warn("Swap area shorter than signature indicates\n");
  		return 0;
***************
*** 2385,2390 ****
--- 2500,2507 ----
  	if (IS_ERR(p))
  		return PTR_ERR(p);
  
+ 	p->shm = NULL;
+ 
  	INIT_WORK(&p->discard_work, swap_discard_work);
  
  	name = getname(specialfile);
***************
*** 2434,2439 ****
--- 2551,2564 ----
  	}
  	swap_header = kmap(page);
  
+ 	/*The first (highest priority) swap partition is the shm area.
+          *Size of the shm area is explicitely specified
+          */
+ 	if(p->is_shm == 1 && mempipe_installed == true) {//nr_swapfiles of the first swap partition equals to 1
+                 swap_header->info.last_page = memswap_init_size;
+                 swap_header->info.nr_badpages = 0;
+         }
+ 
  	maxpages = read_swap_header(p, swap_header, inode);
  	if (unlikely(!maxpages)) {
  		error = -EINVAL;
***************
*** 2523,2531 ****
  		  (swap_flags & SWAP_FLAG_PRIO_MASK) >> SWAP_FLAG_PRIO_SHIFT;
  	enable_swap_info(p, prio, swap_map, cluster_info, frontswap_map);
  
! 	pr_info("Adding %uk swap on %s.  "
  			"Priority:%d extents:%d across:%lluk %s%s%s%s%s\n",
! 		p->pages<<(PAGE_SHIFT-10), name->name, p->prio,
  		nr_extents, (unsigned long long)span<<(PAGE_SHIFT-10),
  		(p->flags & SWP_SOLIDSTATE) ? "SS" : "",
  		(p->flags & SWP_DISCARDABLE) ? "D" : "",
--- 2648,2663 ----
  		  (swap_flags & SWAP_FLAG_PRIO_MASK) >> SWAP_FLAG_PRIO_SHIFT;
  	enable_swap_info(p, prio, swap_map, cluster_info, frontswap_map);
  
! 	if(p->prio == -1){
! 		p->is_shm = 1;
! 	}else{
! 		p->is_shm = 0;
! 	}
! 	
! 
! 	pr_info("Adding %uk swap on %s (is_shm = %d).  "
  			"Priority:%d extents:%d across:%lluk %s%s%s%s%s\n",
! 		p->pages<<(PAGE_SHIFT-10), name->name, p->is_shm, p->prio,
  		nr_extents, (unsigned long long)span<<(PAGE_SHIFT-10),
  		(p->flags & SWP_SOLIDSTATE) ? "SS" : "",
  		(p->flags & SWP_DISCARDABLE) ? "D" : "",
***************
*** 2572,2577 ****
--- 2704,2710 ----
  		putname(name);
  	if (inode && S_ISREG(inode->i_mode))
  		mutex_unlock(&inode->i_mutex);
+ 
  	return error;
  }
  
***************
*** 2718,2723 ****
--- 2851,2857 ----
  	BUG_ON(!PageSwapCache(page));
  	return swap_info[swp_type(swap)];
  }
+ EXPORT_SYMBOL(page_swap_info);
  
  /*
   * out-of-line __page_file_ methods to avoid include hell.
diff -rcNP linux-3.14.4/mm/swap_state.c linux-3.14.4-memSwap/mm/swap_state.c
*** linux-3.14.4/mm/swap_state.c	2014-05-13 07:33:14.000000000 -0400
--- linux-3.14.4-memSwap/mm/swap_state.c	2016-09-05 10:46:53.149074147 -0400
***************
*** 21,26 ****
--- 21,29 ----
  
  #include <asm/pgtable.h>
  
+ extern bool mempipe_installed;
+ extern int (* __my_swap_readpage)(struct page *page);
+ 
  /*
   * swapper_space is a fiction, retained to simplify the path through
   * vmscan's shrink_page_list.
***************
*** 310,315 ****
--- 313,320 ----
  	struct page *found_page, *new_page = NULL;
  	int err;
  
+ 	struct swap_info_struct *sis;
+ 
  	do {
  		/*
  		 * First check the swap cache.  Since this is normally
***************
*** 376,382 ****
  			 * Initiate read into locked page and return.
  			 */
  			lru_cache_add_anon(new_page);
! 			swap_readpage(new_page);
  			return new_page;
  		}
  		radix_tree_preload_end();
--- 381,403 ----
  			 * Initiate read into locked page and return.
  			 */
  			lru_cache_add_anon(new_page);
! 			//swap_readpage(new_page);
! 			
! 			pgoff_t offset;
!         		swp_entry_t entry;
! 		
! 			entry.val = page_private(new_page);
!         		offset = swp_offset(entry);
! 					
! 	
! 			sis = page_swap_info(new_page);
! 			
! 			if(mempipe_installed == true && (offset > 0) && sis->is_shm == 1) {
!                                 __my_swap_readpage(new_page);
!                         }else{
!                                 swap_readpage(new_page);
!                         }
! 
  			return new_page;
  		}
  		radix_tree_preload_end();
diff -rcNP linux-3.14.4/security/tomoyo/builtin-policy.h linux-3.14.4-memSwap/security/tomoyo/builtin-policy.h
*** linux-3.14.4/security/tomoyo/builtin-policy.h	1969-12-31 19:00:00.000000000 -0500
--- linux-3.14.4-memSwap/security/tomoyo/builtin-policy.h	2016-07-15 10:16:24.000000000 -0400
***************
*** 0 ****
--- 1,12 ----
+ static char tomoyo_builtin_profile[] __initdata =
+ "";
+ static char tomoyo_builtin_exception_policy[] __initdata =
+ "initialize_domain /sbin/modprobe from any\n"
+ "initialize_domain /sbin/hotplug from any\n"
+ "";
+ static char tomoyo_builtin_domain_policy[] __initdata =
+ "";
+ static char tomoyo_builtin_manager[] __initdata =
+ "";
+ static char tomoyo_builtin_stat[] __initdata =
+ "";
diff -rcNP linux-3.14.4/security/tomoyo/policy/exception_policy.conf linux-3.14.4-memSwap/security/tomoyo/policy/exception_policy.conf
*** linux-3.14.4/security/tomoyo/policy/exception_policy.conf	1969-12-31 19:00:00.000000000 -0500
--- linux-3.14.4-memSwap/security/tomoyo/policy/exception_policy.conf	2016-07-15 10:16:15.000000000 -0400
***************
*** 0 ****
--- 1,2 ----
+ initialize_domain /sbin/modprobe from any
+ initialize_domain /sbin/hotplug from any
